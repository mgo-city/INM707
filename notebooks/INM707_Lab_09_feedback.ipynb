{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgo-city/INM707/blob/main/notebooks/INM707_Lab_09_feedback.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKQ9wr860S2B"
      },
      "source": [
        "# Lab 09 - Random Search\n",
        "\n",
        "Steps:\n",
        "- Create a policy class with a method to generate perturbations over the policy.\n",
        "- Create a function to evaluate a policy on an environment or a list of environments.\n",
        "- create a simple optimization algorithm that solves dungeon through hill climbing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "adbhyYVx21Qw",
        "outputId": "2e09c291-61db-4dee-f3ad-9565944d540e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/mgo-city/INM707.git\n",
            "  Cloning https://github.com/mgo-city/INM707.git to /tmp/pip-req-build-t542t_gc\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/mgo-city/INM707.git /tmp/pip-req-build-t542t_gc\n",
            "  Resolved https://github.com/mgo-city/INM707.git to commit a882bdb2d3718841b6701e2e3e7b6f6dffea52cc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: dungeon\n",
            "  Building wheel for dungeon (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dungeon: filename=dungeon-0.0.1-py3-none-any.whl size=3907 sha256=366f4e3dfa1d8abe9b6859f7c648af4a39707f1c73b46e8cd1bd11381a54b246\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wp91c11n/wheels/a9/05/b3/b5a73c697d7c0143c5557f13251faac53bd330deaf9731f066\n",
            "Successfully built dungeon\n",
            "Installing collected packages: dungeon\n",
            "Successfully installed dungeon-0.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/mgo-city/INM707.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQrLwPi20BIA"
      },
      "source": [
        "# Loading the dungeon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VuHDH06W0BIC"
      },
      "outputs": [],
      "source": [
        "from dungeon.dungeon import Dungeon, IceDungeon, index_to_actions\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqLbHO4g0BID",
        "outputId": "4762318a-e142-45dd-99d9-98d107e6957d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X X X X X X X X X X \n",
            "X . . . . . X . X X \n",
            "X . . . . . . . . X \n",
            "X . . . . . . . . X \n",
            "X . . . . . . . L X \n",
            "X . . X L . . . L X \n",
            "X . . . X E . . L X \n",
            "X . X . . . . . A X \n",
            "X L . . . . . . . X \n",
            "X X X X X X X X X X \n",
            "\n"
          ]
        }
      ],
      "source": [
        "SIZE_ENVIR = 10\n",
        "\n",
        "my_dungeon = Dungeon(SIZE_ENVIR)\n",
        "my_dungeon.reset()\n",
        "my_dungeon.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgYSlmqK0BIE",
        "outputId": "54e8e56c-4def-46e3-a9d2-66fd70eae9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X X X X X X X X X X \n",
            "X . . . . . X . X X \n",
            "X . . . . . . . . X \n",
            "X . . . . . . . . X \n",
            "X . . . . . . . L X \n",
            "X . . X L . . . L X \n",
            "X . . A X E . . L X \n",
            "X . X . . . . . . X \n",
            "X L . . . . . . . X \n",
            "X X X X X X X X X X \n",
            "\n"
          ]
        }
      ],
      "source": [
        "my_dungeon.reset()\n",
        "my_dungeon.display()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4zellzX0BIF",
        "outputId": "45be34c9-86f4-465f-9e79-aac69d05b3fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'relative_coordinates': array([0, 2]), 'surroundings': array([[0, 0, 0, 0, 0],\n",
            "       [0, 0, 1, 2, 0],\n",
            "       [0, 0, 0, 1, 3],\n",
            "       [0, 1, 0, 0, 0],\n",
            "       [2, 0, 0, 0, 0]], dtype=int8)} -6 False\n",
            "X X X X X X X X X X \n",
            "X . . . . . X . X X \n",
            "X . . . . . . . . X \n",
            "X . . . . . . . . X \n",
            "X . . . . . . . L X \n",
            "X . . X L . . . L X \n",
            "X . . A X E . . L X \n",
            "X . X . . . . . . X \n",
            "X L . . . . . . . X \n",
            "X X X X X X X X X X \n",
            "\n",
            "relative_coordinates\n",
            "[0 2]\n",
            "surroundings\n",
            "[[0 0 0 0 0]\n",
            " [0 0 1 2 0]\n",
            " [0 0 0 1 3]\n",
            " [0 1 0 0 0]\n",
            " [2 0 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "obs, rew, done = my_dungeon.step('up')\n",
        "print(obs, rew, done)\n",
        "my_dungeon.display()\n",
        "for obs_name, o in obs.items():\n",
        "    print(obs_name)\n",
        "    print(o)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcmJxXe10BIF"
      },
      "source": [
        "# 1 - Create a policy class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "PgHfITV9XU5f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy.random import default_rng\n",
        "import math\n",
        "\n",
        "rng = default_rng()\n",
        "\n",
        "class Policy:\n",
        "\n",
        "    def __init__(self, size_hidden):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Declare the different layers\n",
        "\n",
        "        # Surrounding observation layer\n",
        "        self.w_1 = rng.uniform(-math.sqrt(1/25), math.sqrt(1/25), size = (25, size_hidden) )\n",
        "        self.w_2 = rng.uniform(-math.sqrt(1/size_hidden), math.sqrt(1/size_hidden), size = (size_hidden, size_hidden) )\n",
        "        self.b_1 = rng.uniform(-math.sqrt(1/25), math.sqrt(1/25), size = (size_hidden,) )\n",
        "        self.b_2 = rng.uniform(-math.sqrt(1/size_hidden), math.sqrt(1/size_hidden), size = (size_hidden,) )\n",
        "\n",
        "        # Coordinate observation layer\n",
        "        self.w_3 = rng.uniform(-math.sqrt(1/2), math.sqrt(1/2), size = (2, size_hidden) )\n",
        "        self.w_4 = rng.uniform(-math.sqrt(1/size_hidden), math.sqrt(1/size_hidden), size = (size_hidden, size_hidden) )\n",
        "        self.b_3 = rng.uniform(-math.sqrt(1/size_hidden), math.sqrt(1/size_hidden), size = (size_hidden,) )\n",
        "        self.b_4 = rng.uniform(-math.sqrt(1/size_hidden), math.sqrt(1/size_hidden), size = (size_hidden,) )\n",
        "\n",
        "        # Merge layer\n",
        "        self.w_5 = rng.uniform(-math.sqrt(1/(2*size_hidden)), math.sqrt(1/(2*size_hidden)), size = (2*size_hidden, size_hidden) )\n",
        "        self.w_6 = rng.uniform(-math.sqrt(1/size_hidden), math.sqrt(1/size_hidden), size = (size_hidden, 4) )\n",
        "        self.b_5 = rng.uniform(-math.sqrt(1/size_hidden), math.sqrt(1/size_hidden), size = (size_hidden,) )\n",
        "        self.b_6 = rng.uniform(-math.sqrt(1/size_hidden), math.sqrt(1/size_hidden), size = (4,) )\n",
        "\n",
        "        # At initialization, no perturbations\n",
        "        self.theta_w_1 = np.zeros( (25, size_hidden) )\n",
        "        self.theta_w_2 = np.zeros( (size_hidden, size_hidden) )\n",
        "        self.theta_w_3 = np.zeros( (2, size_hidden) )\n",
        "        self.theta_w_4 = np.zeros( (size_hidden, size_hidden) )        \n",
        "        self.theta_w_5 = np.zeros( (2*size_hidden, size_hidden) )        \n",
        "        self.theta_w_6 = np.zeros( (size_hidden, 4) )        \n",
        "\n",
        "        self.theta_b_1 = np.zeros( (size_hidden,) )\n",
        "        self.theta_b_2 = np.zeros( (size_hidden,) )\n",
        "        self.theta_b_3 = np.zeros( (size_hidden,) )\n",
        "        self.theta_b_4 = np.zeros( (size_hidden,) )\n",
        "        self.theta_b_5 = np.zeros( (size_hidden,) )\n",
        "        self.theta_b_6 = np.zeros( (4,) )\n",
        "\n",
        "    def relu(self, x):\n",
        "        return x * (x > 0)\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        return 1/(1 + np.exp(-x))\n",
        "\n",
        "    def select_action(self, x):\n",
        "\n",
        "        s = x[2:]\n",
        "        c = x[:2]\n",
        "\n",
        "        # Declare how the data flows from input x to output.\n",
        "        s = self.sigmoid(self.w_1.T @ s + self.theta_w_1.T @ s + self.b_1 + self.theta_b_1)\n",
        "        s = self.sigmoid(self.w_2.T @ s + self.theta_w_2.T @ s + self.b_2 + self.theta_b_2)\n",
        "\n",
        "        c = self.sigmoid(self.w_3.T @ c + self.theta_w_3.T @ c + self.b_3 + self.theta_b_3)\n",
        "        c = self.sigmoid(self.w_4.T @ c + self.theta_w_4.T @ c + self.b_4 + self.theta_b_4)\n",
        "\n",
        "        repr = np.concatenate([c, s])\n",
        "\n",
        "        repr = self.sigmoid(self.w_5.T @ repr + self.theta_w_5.T @ repr + self.b_5 + self.theta_b_5)\n",
        "        repr = self.w_6.T @ repr + self.theta_w_6.T @ repr + self.b_6 + self.theta_b_6\n",
        "\n",
        "        output = np.argmax(repr)\n",
        "\n",
        "        return output\n",
        "\n",
        "    def perturbate_policy(self, scale):\n",
        "\n",
        "        # We perturbate only one branch of the processing\n",
        "\n",
        "        branch = rng.choice(['s', 'c', 'repr'])\n",
        "\n",
        "        self.theta_w_1 = np.zeros(self.theta_w_1.shape)\n",
        "        self.theta_w_2 = np.zeros(self.theta_w_2.shape)\n",
        "        self.theta_b_1 = np.zeros(self.b_1.shape )\n",
        "        self.theta_b_2 = np.zeros(self.b_2.shape )\n",
        "\n",
        "        self.theta_w_3 = np.zeros(self.theta_w_3.shape)\n",
        "        self.theta_w_4 = np.zeros(self.theta_w_4.shape)\n",
        "        self.theta_b_3 = np.zeros(self.b_3.shape )\n",
        "        self.theta_b_4 = np.zeros(self.b_4.shape )\n",
        "\n",
        "        self.theta_w_5 = np.zeros(self.theta_w_5.shape)\n",
        "        self.theta_w_6 = np.zeros(self.theta_w_6.shape)\n",
        "        self.theta_b_5 = np.zeros(self.b_5.shape )\n",
        "        self.theta_b_6 = np.zeros(self.b_6.shape )\n",
        "\n",
        "\n",
        "        if branch == 's':\n",
        "          self.theta_w_1 = rng.normal( scale = scale, size = self.theta_w_1.shape)\n",
        "          self.theta_w_2 = rng.normal( scale = scale, size = self.theta_w_2.shape)\n",
        "          self.theta_b_1 = rng.normal(scale = scale, size = self.b_1.shape )\n",
        "          self.theta_b_2 = rng.normal(scale = scale, size = self.b_2.shape )\n",
        "\n",
        "        elif branch == 'c':\n",
        "          self.theta_w_3 = rng.normal( scale = scale, size = self.theta_w_3.shape)\n",
        "          self.theta_w_4 = rng.normal( scale = scale, size = self.theta_w_4.shape)\n",
        "          self.theta_b_3 = rng.normal(scale = scale, size = self.b_3.shape )\n",
        "          self.theta_b_4 = rng.normal(scale = scale, size = self.b_4.shape )\n",
        "\n",
        "        elif branch == 'repr':\n",
        "          self.theta_w_5 = rng.normal( scale = scale, size = self.theta_w_5.shape)\n",
        "          self.theta_w_6 = rng.normal( scale = scale, size = self.theta_w_6.shape)\n",
        "          self.theta_b_5 = rng.normal(scale = scale, size = self.b_5.shape )\n",
        "          self.theta_b_6 = rng.normal(scale = scale, size = self.b_6.shape )\n",
        "\n",
        "        else:\n",
        "          raise ValueError\n",
        "\n",
        "    def update_policy(self):\n",
        "\n",
        "        self.w_1 += self.theta_w_1\n",
        "        self.w_2 += self.theta_w_2\n",
        "        self.w_3 += self.theta_w_3\n",
        "        self.w_4 += self.theta_w_4\n",
        "        self.w_5 += self.theta_w_5\n",
        "        self.w_6 += self.theta_w_6\n",
        "\n",
        "        self.b_1 += self.theta_b_1\n",
        "        self.b_2 += self.theta_b_2\n",
        "        self.b_3 += self.theta_b_3\n",
        "        self.b_4 += self.theta_b_4\n",
        "        self.b_5 += self.theta_b_5\n",
        "        self.b_6 += self.theta_b_6\n",
        "\n",
        "def convert_state(state, N):\n",
        "\n",
        "    c = state['relative_coordinates'].flatten()\n",
        "    o = state['surroundings'].flatten()\n",
        "\n",
        "    c = c / N\n",
        "    o = o / 4 - 0.5\n",
        "\n",
        "    state = np.concatenate( [c,o] )\n",
        "    \n",
        "    return state"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cbc05qmW0BIJ"
      },
      "source": [
        "# 2: Evaluate Policy on Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "N33suzPi0BIJ"
      },
      "outputs": [],
      "source": [
        "def run_policy_on_environment(policy, dungeon, time_limit):\n",
        "\n",
        "  state = dungeon.reset()\n",
        "  cumulative_reward = 0\n",
        "  t = 0\n",
        "\n",
        "  while t < time_limit:\n",
        "    \n",
        "    state = convert_state(state, dungeon.size)\n",
        "    action = policy.select_action(state)\n",
        "    action_name = index_to_actions[action].name \n",
        "\n",
        "    state, reward, done = dungeon.step(action_name)\n",
        "\n",
        "    cumulative_reward += reward\n",
        "    \n",
        "    if done:\n",
        "      return cumulative_reward\n",
        "\n",
        "    t += 1\n",
        "\n",
        "  return -10000\n",
        "\n",
        "\n",
        "def evaluate_policy(policy, episodes, time_limit, N):\n",
        "\n",
        "  returns = []\n",
        "  \n",
        "  for episode in range(episodes):\n",
        "    dungeon = Dungeon(N)\n",
        "  \n",
        "    returns.append(run_policy_on_environment(policy, dungeon, time_limit))\n",
        "\n",
        "  return sum(returns)/len(returns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w5KRGVb0BIK"
      },
      "source": [
        "# 3 - Simple optimization loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmJVrk3X0BIK",
        "outputId": "fce7c0d6-efad-4e51-ef64-1219c604ab51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization step 0, objective -648.15\n",
            "Optimization step 1, objective -589.5\n",
            "Optimization step 6, objective -589.25\n",
            "Optimization step 16, objective -522.05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-56-0754afe08dc3>:51: RuntimeWarning: overflow encountered in exp\n",
            "  return 1/(1 + np.exp(-x))\n"
          ]
        }
      ],
      "source": [
        "SIZE_ENVIR = 10\n",
        "N_STEPS = 100000\n",
        "\n",
        "policy = Policy(128)\n",
        "\n",
        "objective = evaluate_policy(policy, 20, 50, SIZE_ENVIR)\n",
        "results = []\n",
        "\n",
        "for i in range(N_STEPS):\n",
        "  policy.perturbate_policy(scale = 10*(N_STEPS - i) / N_STEPS)\n",
        "  new_obj = evaluate_policy(policy, 3, 100, SIZE_ENVIR)\n",
        "\n",
        "  if new_obj > objective:\n",
        "\n",
        "    # verify with more eval\n",
        "    new_obj_check = evaluate_policy(policy, 20, 100, SIZE_ENVIR)\n",
        "    if not new_obj_check > objective:\n",
        "      continue\n",
        "    \n",
        "    policy.update_policy()\n",
        "    objective = new_obj_check\n",
        "    print( f\"Optimization step {i}, objective {objective}\")\n",
        "    results.append([i, objective])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6dqVGeZ_BtF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}