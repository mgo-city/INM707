{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTRcz+q7yLiYKKImV5EisS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgo-city/INM707/blob/main/notebooks/INM707_Lab_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gymnasium"
      ],
      "metadata": {
        "id": "PRB_mumU56M_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U \"ray[rllib]\""
      ],
      "metadata": {
        "id": "lDQvBf8--2P1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwzdCCEo4M2e"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/mgo-city/INM707-lab06.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dungeon.dungeon import Dungeon, index_to_actions"
      ],
      "metadata": {
        "id": "jPE4JX0o5Z5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "W1zkSOEx5j4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DungeonEnv(gym.Env):\n",
        "\n",
        "    def __init__(self, render_mode=None, size=5):\n",
        "        self.size = size  # The size of the Dungeon\n",
        "\n",
        "        # Observations are dictionaries with the agent's and the target's location.\n",
        "        # Each location is encoded as an element of {0, ..., `size`}^2, i.e. MultiDiscrete([size, size]).\n",
        "        self.observation_space = spaces.Dict(\n",
        "            {\n",
        "                \"relative_coordinates\": spaces.Box(-size, size , shape=(2,), dtype=int),\n",
        "                \"surroundings\": spaces.Box(0, 4, shape=(5, 5), dtype=int)\n",
        "            }\n",
        "        )\n",
        "\n",
        "        # We have 4 actions, corresponding to \"right\", \"up\", \"left\", \"down\"\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        self.render_mode = \"ansi\"\n",
        "\n",
        "        self.clock = None\n",
        "\n",
        "        self._dungeon_env = Dungeon(size)\n",
        "        self._dungeon_env.reset()\n",
        "\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        # We need the following line to seed self.np_random\n",
        "        super().reset(seed=seed)\n",
        "\n",
        "        obs = self._dungeon_env.reset()\n",
        "\n",
        "        return obs, {}\n",
        "\n",
        "    def step(self, action):\n",
        "\n",
        "        act = index_to_actions[action]\n",
        "\n",
        "        observations, reward, done = self._dungeon_env.step(act.name)\n",
        "\n",
        "        return observations, reward, done, False, {}\n",
        "\n",
        "    def render(self):\n",
        "\n",
        "        envir_with_agent = self._dungeon_env.dungeon.copy()\n",
        "        envir_with_agent[self._dungeon_env.position_agent[0], self._dungeon_env.position_agent[1]] = 4\n",
        "        \n",
        "        full_repr = \"\"\n",
        "\n",
        "        for r in range(self.size):\n",
        "            \n",
        "            line = \"\"\n",
        "            \n",
        "            for c in range(self.size):\n",
        "\n",
        "                string_repr = self._dungeon_env.dict_map_display[ envir_with_agent[r,c] ]\n",
        "                \n",
        "                line += \"{0:2}\".format(string_repr)\n",
        "\n",
        "            full_repr += line + \"\\n\"\n",
        "\n",
        "        return full_repr\n"
      ],
      "metadata": {
        "id": "-96WZ-Ul52zN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dungeon_env = DungeonEnv(size=100)\n"
      ],
      "metadata": {
        "id": "_hMyUey_IMjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dungeon_env.render()\n",
        "dungeon_env.step(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu9H6e_WITtc",
        "outputId": "76215d18-6593-43cf-8a01-c0c85cd23745"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'relative_coordinates': array([80,  8]),\n",
              "  'surroundings': array([[0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0],\n",
              "         [0, 0, 0, 0, 0]], dtype=int8)},\n",
              " -1,\n",
              " False,\n",
              " False,\n",
              " {})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ray\n",
        "from ray.rllib.algorithms import ppo, dqn\n",
        "from ray.tune.logger import pretty_print"
      ],
      "metadata": {
        "id": "OsLtox2e-ZHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ray.shutdown()\n",
        "ray.init()\n",
        "\n",
        "algo = dqn.DQN(env=DungeonEnv, config={\n",
        "    \"env_config\": {\"size\":40},  # config to pass to env class\n",
        "})\n",
        "\n",
        "while True:\n",
        "    metrics = algo.train()\n",
        "    mean_reward = metrics['episode_reward_mean']\n",
        "    print(mean_reward)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BH5E9xsY_Sfw",
        "outputId": "3e534ce5-e477-41f3-8df2-7eefed5ddf83"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-29 09:49:54,517\tINFO worker.py:1553 -- Started a local Ray instance.\n",
            "2023-03-29 09:49:55,875\tWARNING deprecation.py:50 -- DeprecationWarning: `algo = Algorithm(env='<class '__main__.DungeonEnv'>', ...)` has been deprecated. Use `algo = AlgorithmConfig().environment('<class '__main__.DungeonEnv'>').build()` instead. This will raise an error in the future!\n",
            "2023-03-29 09:49:55,882\tINFO algorithm_config.py:2899 -- Your framework setting is 'tf', meaning you are using static-graph mode. Set framework='tf2' to enable eager execution with tf2.x. You may also then want to set eager_tracing=True in order to reach similar execution speed as with static-graph mode.\n",
            "2023-03-29 09:49:55,916\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
            "2023-03-29 09:49:55,930\tWARNING env.py:156 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.\n",
            "2023-03-29 09:49:55,935\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset.\n",
            "2023-03-29 09:49:59,099\tWARNING util.py:67 -- Install gputil for GPU system monitoring.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-129.22727272727272\n",
            "-90.43\n",
            "-53.1588785046729\n",
            "-16.818791946308725\n",
            "-8.548022598870057\n",
            "3.975103734439834\n",
            "7.466666666666667\n",
            "12.91304347826087\n",
            "14.160112359550562\n",
            "16.214833759590793\n",
            "17.646924829157175\n",
            "16.68421052631579\n",
            "17.707207207207208\n",
            "16.004878048780487\n",
            "17.611494252873563\n",
            "17.71461187214612\n",
            "17.439080459770114\n",
            "18.45274725274725\n",
            "17.53211009174312\n",
            "16.953161592505854\n",
            "17.72645739910314\n",
            "16.656324582338904\n",
            "17.301149425287356\n",
            "18.334792122538293\n",
            "16.546762589928058\n",
            "16.546762589928058\n",
            "17.762013729977117\n",
            "17.35198135198135\n",
            "16.785714285714285\n",
            "18.59090909090909\n",
            "17.931662870159453\n",
            "16.45145631067961\n",
            "17.550925925925927\n",
            "17.62700228832952\n",
            "17.54691075514874\n",
            "17.143187066974598\n",
            "17.904017857142858\n",
            "17.208333333333332\n",
            "16.89125295508274\n",
            "17.210772833723652\n",
            "17.172897196261683\n",
            "18.250554323725055\n",
            "17.97566371681416\n",
            "17.041570438799077\n",
            "17.494226327944574\n",
            "17.807256235827666\n",
            "16.962962962962962\n",
            "16.95294117647059\n",
            "17.99772727272727\n",
            "17.76233183856502\n",
            "17.483069977426638\n",
            "17.185446009389672\n",
            "17.348729792147807\n",
            "16.406698564593302\n",
            "18.48898678414097\n",
            "18.10158013544018\n",
            "17.69495412844037\n",
            "17.568181818181817\n",
            "17.620137299771166\n",
            "17.743764172335602\n",
            "17.452272727272728\n",
            "17.193473193473192\n",
            "16.97459584295612\n",
            "17.537585421412302\n",
            "17.23094688221709\n",
            "18.111607142857142\n",
            "16.375\n",
            "17.432183908045978\n",
            "17.884615384615383\n",
            "17.128504672897197\n",
            "17.80593607305936\n",
            "17.97327394209354\n",
            "17.348837209302324\n",
            "17.238979118329468\n",
            "17.0554272517321\n",
            "17.29952830188679\n",
            "17.113163972286372\n",
            "18.070953436807095\n",
            "17.064965197215777\n",
            "18.346491228070175\n",
            "16.897374701670646\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uXRWJuiLG4fq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}